{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Modelling and Evaluation Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Answer business requirement 2: \n",
        "    * The client is interested in predicting if a cherry tree is healthy or contains powdery mildew.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cherry-leaves/cherry-leaves/train\n",
        "* inputs/cherry-leaves/cherry-leaves/test\n",
        "* inputs/cherry-leaves/cherry-leaves/validation\n",
        "* image shape embeddings.\n",
        "\n",
        "## Outputs\n",
        "* Images distribution plot in train, validation, and test set.\n",
        "* Image augmentation.\n",
        "* Class indices to change prediction inference in labels.\n",
        "* Machine learning model creation and training.\n",
        "* Save model.\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation on pickle file.\n",
        "* Prediction on the random image file.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oPUd1K_qCr"
      },
      "source": [
        "# Import regular packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r /workspace/powdery_mildew_detector/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "oqqga261_w4N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oPUd1K_qCr"
      },
      "source": [
        "# Set Working Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the notebooks are within a subfolder, we need to change the working directory when running the notebook in the editor.\n",
        "\n",
        "We need to change the working directory from its current folder to its parent folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SooBUDWVIQK"
      },
      "outputs": [],
      "source": [
        "## We access the current directory\n",
        "cwd= os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ7j8jHhmYDD"
      },
      "outputs": [],
      "source": [
        "## We set the parent of the current directory the new current directory\n",
        "os.chdir('/workspace/powdery_mildew_detector')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b107Zs3TmYDD"
      },
      "outputs": [],
      "source": [
        "## View current work directory is correct\n",
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czVrQtLccTJb"
      },
      "source": [
        "## Set input directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx2ZqnpDcY2H"
      },
      "source": [
        "Set train, validation and test paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5eucaA9M6qz1"
      },
      "outputs": [],
      "source": [
        "## Set input directories for train, validation and test\n",
        "my_data_dir = 'inputs/cherry-leaves/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czVrQtLccTJb"
      },
      "source": [
        "## Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Set output directory with the correct version directory\n",
        "version = 'v11'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czVrQtLccTJb"
      },
      "source": [
        "## Set labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntzIpcxb3oIE"
      },
      "outputs": [],
      "source": [
        "## Set label names\n",
        "labels = os.listdir(train_path)\n",
        "\n",
        "print(\n",
        "    f\"Project Labels: {labels}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import saved image shape embedding\n",
        "import joblib\n",
        "version = 'v11'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSTKDM0XvuVu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ0p1nYJ_3sx"
      },
      "source": [
        "# Number of images in train, test and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'labels' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlabels\u001b[49m:\n\u001b[1;32m      7\u001b[0m         folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(my_data_dir, folder, label)\n\u001b[1;32m      8\u001b[0m         num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(folder_path))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ],
      "source": [
        "## Show plot with number of images in train, test and validation sets\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "        folder_path = os.path.join(my_data_dir, folder, label)\n",
        "        num_images = len(os.listdir(folder_path))\n",
        "        \n",
        "        all_data.append({\n",
        "            'Set': folder,\n",
        "            'Label': label,\n",
        "            'Frequency': num_images\n",
        "        })\n",
        "\n",
        "# Create the DataFrame in one go\n",
        "df_freq = pd.DataFrame(all_data)\n",
        "\n",
        "print(df_freq)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp4l-B11vCiP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qved3ALYLrng"
      },
      "source": [
        "# Image data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "BMU8_F6ZAfjS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Initialize ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "nIkD9esZAhTm"
      },
      "outputs": [],
      "source": [
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Augment training image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08qYmeq3FE-e"
      },
      "outputs": [],
      "source": [
        "batch_size = 20  # Set batch size\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "train_set.class_indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cAwum1tWsmz"
      },
      "source": [
        "* ### Augment validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi6LZ9oJMPHB"
      },
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxDzlWdBXGGI"
      },
      "source": [
        "### Augment test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egJ0XQSkQZ7i"
      },
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Scipy Package, as it is not installed via requirements.txt\n",
        "pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Plot augmented training images\n",
        "for _ in range(3):\n",
        "    # img, label = train_set.next()\n",
        "    img, label = next(iter(train_set))\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Plot augmented validatíon images\n",
        "for _ in range(3):\n",
        "    # img, label = validation_set.next()\n",
        "    img, label = next(iter(train_set))\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Plot augmented test images\n",
        "for _ in range(3):\n",
        "    # img, label = test_set.next()\n",
        "    img, label = next(iter(train_set))\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxFqIpblnaDI"
      },
      "source": [
        "## Save class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c60wT9Nvnaht"
      },
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp4l-B11vCiP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qved3ALYLrng"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp60ceJkvFab"
      },
      "source": [
        "## ML model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    ## First Convolutional Layer\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    ## Second Convolutional Layer\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    ## Third Convolutional Layer\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    ## Flatten the layers\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    ## Fully Connected Layer\n",
        "    model.add(Dense(63, activation='relu'))\n",
        "\n",
        "    ## Dropout layer to prevent overfitting\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    ## Output Layer\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    \n",
        "    ## Compile Model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Model Summary "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0fnaUSeBTFy"
      },
      "outputs": [],
      "source": [
        "## Model Summery\n",
        "create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Early Stopping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Early Stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Sv_Nlfzr5F"
      },
      "source": [
        "## Fit model for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHD-ggqiB3zV"
      },
      "outputs": [],
      "source": [
        "## Fit Model for training\n",
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtuBjjzFiQRh"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Save Model in Keras file format\n",
        "model.save('outputs/v11/cherry_leaves_model.keras')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp4l-B11vCiP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qved3ALYLrng"
      },
      "source": [
        "# Model Performace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uESgICbOztUi"
      },
      "source": [
        "## Model learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inzjI5Ve2UVi"
      },
      "outputs": [],
      "source": [
        "## Plot learning history curves\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I41227LlqtV"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Scikit-Learn Package\n",
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load Saved Model\n",
        "import sklearn\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score, roc_curve, auc, roc_auc_score\n",
        "from keras.models import load_model\n",
        "# model = load_model('outputs/v1/cherry_leaves_model.h5')\n",
        "model = load_model('outputs/v11/cherry_leaves_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Plot Confusion Matrix\n",
        "validation_set.reset()\n",
        "\n",
        "\n",
        "x_true, y_true = next(test_set)\n",
        "preds = np.argmax(model.predict(test_set), axis=1)\n",
        "y_pred = np.rint(preds)\n",
        "y_true = test_set.labels\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "sns_colours = sns.diverging_palette(20, 145, as_cmap=True)\n",
        "\n",
        "\n",
        "classes=list(test_set.class_indices.keys())\n",
        "length = len(classes)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap=sns_colours)       \n",
        "plt.xticks(np.arange(length) + .5, classes, rotation=0, fontsize=8)\n",
        "plt.yticks(np.arange(length) + .3, classes, rotation=90, fontsize=8)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Load saved model and save as Best Model\n",
        "best_model = load_model(\"outputs/v11/cherry_leaves_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Print Test Accuracy for test set\n",
        "test_loss, test_accuracy = best_model.evaluate(test_set)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate accuracy and generate predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reset the test set iterator, calculates the true labels, and generates predictions for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset the test set iterator\n",
        "test_set.reset()\n",
        "\n",
        "# Generate predictions\n",
        "y_true = test_set.classes\n",
        "y_pred = best_model.predict(test_set, verbose=1)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate classification report - A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generates and prints a standard classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "general_report = classification_report(y_true, y_pred_classes, target_names=labels)\n",
        "print(\"Classification Report for Model A:\\n\", general_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate classification report - B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generates a classification report and visualizes it as a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_report_heatmap = classification_report(y_true, y_pred_classes, target_names=labels, output_dict=True)\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "sns.heatmap(pd.DataFrame(classification_report_heatmap).iloc[:-1, :].T, annot=True, cmap=\"Blues\", cbar=False, linewidths=1)\n",
        "plt.title('Classification Report')\n",
        "plt.savefig(f'{file_path}/classification_report_heatmap.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots and saves the ROC curve for each class in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "true_positive_rate = {}\n",
        "false_positive_rate = {}\n",
        "roc_auc = {}\n",
        "for i, label in enumerate(labels):\n",
        "    false_positive_rate[label], true_positive_rate[label], _ = roc_curve(y_true == i, y_pred[:, i])\n",
        "    roc_auc[label] = auc(false_positive_rate[label], true_positive_rate[label])\n",
        "\n",
        "plt.figure()\n",
        "for label in labels:\n",
        "    plt.plot(false_positive_rate[label], true_positive_rate[label], label=f'ROC curve (area = {roc_auc[label]:.2f}) for {label}')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(f'{file_path}/roc_curve.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auo3VPdvmVL1"
      },
      "source": [
        "Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dsaUbtSlK8V"
      },
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save evaluation pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f\"outputs/v11/evaluation.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtuBjjzFiQRh"
      },
      "source": [
        "## Predict on new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt6Esizw677F"
      },
      "source": [
        "Load a random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz-NL2mXaczH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 99\n",
        "label = labels[0]  # select healthy (0) or powdery mildew (1)  \n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QweywGMLm_0V"
      },
      "source": [
        "Convert image to array and prepare for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwoIvJWQcitQ"
      },
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCS7g3CenGJE"
      },
      "source": [
        "Predict class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkFoAMtUdEO2"
      },
      "outputs": [],
      "source": [
        "pred_proba = model.predict(my_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_proba < 0.5]\n",
        "\n",
        "if pred_class == target_map[1]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "print(pred_proba)\n",
        "print(pred_class)\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RtitT7v-xv"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZcmA1wG8AdC"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5erRLQ2b3mh_"
      },
      "source": [
        "## Push generated/new files from this Session to your GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNJsZ5UeQDG"
      },
      "source": [
        "* .gitignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cat .gitignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNJsZ5UeQDG"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNJsZ5UeQDG"
      },
      "source": [
        "* Git add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1kUQ0VIoi4c"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git commit -am \"New model v11\" \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkyUs70oloW"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
